{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "# !{sys.executable} -m pip install --upgrade pip\n",
    "# !{sys.executable} -m pip install numpy\n",
    "# !{sys.executable} -m pip install scikit-image\n",
    "# !{sys.executable} -m pip install matplotlib\n",
    "# !{sys.executable} -m pip install scikit-learn\n",
    "# !{sys.executable} -m pip install h5py\n",
    "# !{sys.executable} -m pip install pandas\n",
    "# !{sys.executable} -m pip install tables\n",
    "# !{sys.executable} -m pip install requests\n",
    "# !{sys.executable} -m pip install Glymur\n",
    "# !{sys.executable} -m pip install tqdm\n",
    "# !{sys.executable} -m pip install opencv-python\n",
    "# !{sys.executable} -m pip install keras\n",
    "# !{sys.executable} -m pip install tensorflow\n",
    "# !{sys.executable} -m pip install seaborn\n",
    "# !{sys.executable} -m pip install ipyparallel\n",
    "# !{sys.executable} -m pip install pyarrow\n",
    "# !{sys.executable} -m pip install swifter\n",
    "# !{sys.executable} -m pip install pandarallel\n",
    "# !{sys.executable} -m pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { white-space: pre !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "import multiprocessing as mp\n",
    "from glob import glob\n",
    "from IPython.core.display import HTML\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glymur\n",
    "import cv2\n",
    "import requests\n",
    "import json\n",
    "import hashlib\n",
    "import random\n",
    "import itertools\n",
    "from joblib import Parallel, delayed, parallel_backend\n",
    "import time\n",
    "import warnings\n",
    "from jupyterthemes import jtplot\n",
    "import swifter\n",
    "\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.patches import Rectangle\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy import ndimage as ndi\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict, GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage import data\n",
    "from skimage.filters import threshold_yen, threshold_triangle, threshold_otsu, threshold_li, sobel\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import label, regionprops\n",
    "from skimage.morphology import closing, square\n",
    "from skimage.color import label2rgb\n",
    "from skimage import exposure\n",
    "from skimage.io import imread\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.measure import label\n",
    "from skimage import color\n",
    "from skimage.transform import resize, rescale\n",
    "from skimage.feature import hog\n",
    "\n",
    "\n",
    "rescale_size = (150, 270)\n",
    "display(HTML(\"<style>pre { white-space: pre !important; }</style>\"))\n",
    "num_cores = mp.cpu_count()\n",
    "plt.rcParams.update({'figure.max_open_warning': 0})\n",
    "warnings.filterwarnings('ignore')\n",
    "# jtplot.style(theme=\"monokai\", context=\"notebook\", ticks=True, grid=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42904\n",
      "158476\n",
      "249801\n",
      "x_tile                                    1\n",
      "y_tile                                    1\n",
      "x_hirise                                420\n",
      "y_hirise                                324\n",
      "PlanetocentricLatitude             -85.5041\n",
      "PlanetographicLatitude             -85.5567\n",
      "PositiveEast360Longitude            104.952\n",
      "BodyFixedCoordinateX               -68.3807\n",
      "BodyFixedCoordinateY                256.056\n",
      "BodyFixedCoordinateZ               -3370.64\n",
      "tile_id                          APF0000cwz\n",
      "obsid                       ESP_012079_0945\n",
      "Name: 0, dtype: object\n",
      "ESP_012079_0945\n",
      "       x_tile  y_tile  x_hirise  y_hirise  PlanetocentricLatitude  PlanetographicLatitude  PositiveEast360Longitude  BodyFixedCoordinateX  BodyFixedCoordinateY  BodyFixedCoordinateZ     tile_id            obsid\n",
      "0           1       1     420.0     324.0              -85.504144              -85.556701                104.952104            -68.380674            256.056147          -3370.636698  APF0000cwz  ESP_012079_0945\n",
      "1           1       2     420.0     872.0              -85.502300              -85.554878                104.934805            -68.331337            256.181661          -3370.628630  APF0000ck9  ESP_012079_0945\n",
      "2           1       3     420.0    1420.0              -85.500454              -85.553054                104.917486            -68.281853            256.307249          -3370.620295  APF0000cty  ESP_012079_0945\n",
      "3           1       4     420.0    1968.0              -85.498607              -85.551229                104.900198            -68.232522            256.433112          -3370.615690  APF0000ciy  ESP_012079_0945\n",
      "4           1       5     420.0    2516.0              -85.496762              -85.549404                104.882968            -68.183281            256.558509          -3370.606455  APF0000cwp  ESP_012079_0945\n",
      "...       ...     ...       ...       ...                     ...                     ...                       ...                   ...                   ...                   ...         ...              ...\n",
      "42899       2      41    1160.0   22244.0              -81.317022              -81.417411                295.697530            221.306585           -459.891857          -3341.920182  APF0000ib0  ESP_022699_0985\n",
      "42900       2      42    1160.0   22792.0              -81.312098              -81.412542                295.693292            221.396980           -460.166815          -3341.874557  APF0000ibd  ESP_022699_0985\n",
      "42901       2      43    1160.0   23340.0              -81.307170              -81.407669                295.689270            221.489427           -460.441688          -3341.833083  APF0000ib2  ESP_022699_0985\n",
      "42902       2      44    1160.0   23888.0              -81.302245              -81.402799                295.685471            221.583849           -460.716174          -3341.795842  APF0000id7  ESP_022699_0985\n",
      "42903       2      45    1160.0   24436.0              -81.297312              -81.397922                295.681636            221.678080           -460.991080          -3341.757629  APF0000id9  ESP_022699_0985\n",
      "\n",
      "[42904 rows x 12 columns]\n",
      "       marking_id   angle  distance     tile_id  image_x   image_y  n_votes            obsid  spread  version  ...  y_angle      l_s  map_scale  north_azimuth  BodyFixedCoordinateX  BodyFixedCoordinateY  BodyFixedCoordinateZ  PlanetocentricLatitude  PlanetographicLatitude   Longitude\n",
      "0         F000000  205.56    179.71  APF0000ci9  2270.76  24336.16       35  ESP_012079_0945   88.03        1  ...    -0.43  214.785       0.25     126.856883            -65.804336            261.407884          -3370.504345              -85.427383              -85.480829  104.129523\n",
      "1         F000001  185.39    179.62  APF0000cia  3391.21   5640.60       15  ESP_012079_0945   21.35        1  ...    -0.09  214.785       0.25     126.856883            -67.219114            257.011589          -3370.631413              -85.493546              -85.546226  104.656897\n",
      "2         F000002  184.98    500.27  APF0000cia  3509.96   5876.70       10  ESP_012079_0945   18.91        1  ...    -0.09  214.785       0.25     126.856883            -67.170611            257.055226          -3370.630794              -85.493039              -85.545725  104.644396\n",
      "3         F000004  184.29    105.43  APF0000cia  3716.27   5824.50        6  ESP_012079_0945   26.41        1  ...    -0.07  214.785       0.25     126.856883            -67.127761            257.024926          -3370.635002              -85.493723              -85.546401  104.637107\n",
      "4         F000005  189.42    109.50  APF0000cia  3452.17   6033.00        3  ESP_012079_0945   22.58        1  ...    -0.16  214.785       0.25     126.856883            -67.169940            257.096267          -3370.628302              -85.492368              -85.545061  104.642019\n",
      "...           ...     ...       ...         ...      ...       ...      ...              ...     ...      ...  ...      ...      ...        ...            ...                   ...                   ...                   ...                     ...                     ...         ...\n",
      "158471    F02bc86   87.64     87.78  APF0000lzw  1120.29  14752.23       23  ESP_020941_0980   45.85        1  ...     1.00  216.966       0.50     111.375196            198.639892            449.570185          -3344.502373              -81.639810              -81.736574   66.162049\n",
      "158472    F02bc87   64.02     91.47  APF0000lzw  1474.27  14764.35       21  ESP_020941_0980   43.80        1  ...     0.89  216.966       0.50     111.375196            198.769924            449.450441          -3344.512864              -81.640791              -81.737544   66.142540\n",
      "158473    F02bc89   62.42     68.26  APF0000lzw  1071.98  14821.38       14  ESP_020941_0980   48.83        1  ...     0.88  216.966       0.50     111.375196            198.646759            449.611070          -3344.495779              -81.639120              -81.735892   66.163243\n",
      "158474    F02bc8a   53.25    100.43  APF0000lzw  1478.67  14839.67        6  ESP_020941_0980   62.34        1  ...     0.80  216.966       0.50     111.375196            198.797635            449.474974          -3344.507184              -81.640213              -81.736972   66.140742\n",
      "158475    F02bc8b  111.03     93.02  APF0000q5w   757.50  13341.33        3  ESP_022193_0950    4.01        1  ...     0.93  278.375       0.50     118.334067             -8.347034            287.072738          -3369.222728              -85.127859              -85.184775   91.665484\n",
      "\n",
      "[158476 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "drive_location = \"/Users/Utkarsh/OneDrive - University of Toronto/SURF 2020/Code\"\n",
    "data_location = drive_location + '/data'\n",
    "P4data_location = drive_location + \"/P4 data\"\n",
    "glob(P4data_location + \"/*.csv\")\n",
    "\n",
    "metadata = pd.read_csv(P4data_location + '/P4_catalog_v1.1_metadata.csv')\n",
    "tiles_coord = pd.read_csv(P4data_location + '/P4_catalog_v1.1_tile_coords_final.csv')\n",
    "fan = pd.read_csv(P4data_location + \"/P4_catalog_v1.1_L1C_cut_0.5_fan.csv\")\n",
    "blotch = pd.read_csv(P4data_location + \"/P4_catalog_v1.1_L1C_cut_0.5_blotch.csv\")\n",
    "\n",
    "print(len(tiles_coord))\n",
    "print(len(fan))\n",
    "print(len(blotch))\n",
    "\n",
    "item = tiles_coord.iloc[0].obsid\n",
    "print(tiles_coord.iloc[0])\n",
    "print(item)\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "print(tiles_coord)\n",
    "print(fan)\n",
    "pd.set_option('display.expand_frame_repr', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def download_file(filename):\n",
    "    savename = data_location + \"/{filename}_RGB.NOMAP.JP2\".format(filename=filename)\n",
    "    if os.path.exists(savename):\n",
    "        print(\"{} exists\".format(savename))\n",
    "        return\n",
    "    components = filename.split(\"_\")\n",
    "    l = 100*int(int(components[1])/100)\n",
    "    h = 100*int(1+int(components[1])/100)-1\n",
    "    url=\"https://hirise-pds.lpl.arizona.edu/download/PDS/EXTRAS/RDR/ESP/ORB_{low:06d}_{high:06d}/{filename}/{filename}_RGB.NOMAP.JP2\".format(low=l,high=h,filename=filename)\n",
    "    print(url)\n",
    "    myfile = requests.get(url)\n",
    "    with open(savename, 'wb') as file:\n",
    "      file.write(myfile.content)\n",
    "      file.flush()\n",
    "      file.close()\n",
    "    \n",
    "def load_file(filename):\n",
    "    savename = data_location + \"/{filename}_RGB.NOMAP.JP2\".format(filename=filename)\n",
    "    if not os.path.exists(savename):\n",
    "        download_file(filename)\n",
    "    return glymur.Jp2k(savename)\n",
    "\n",
    "\n",
    "nx,ny = 840, 648\n",
    "\n",
    "def cv2_imshow(a, **kwargs):\n",
    "    a = a.clip(0, 255).astype('uint8')\n",
    "    # cv2 stores colors as BGR; convert to RGB\n",
    "    if a.ndim == 3:\n",
    "        if a.shape[2] == 4:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGRA2RGBA)\n",
    "        else:\n",
    "            a = cv2.cvtColor(a, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return plt.imshow(a, **kwargs)\n",
    "\n",
    "def fan_mask(fan, tile):\n",
    "    xc,yc = fan.image_x - (tile.x_hirise-nx//2),fan.image_y - (tile.y_hirise-ny//2)\n",
    "    \n",
    "    fan_s = fan.distance / (1+np.tan(np.deg2rad(fan.spread//2)))\n",
    "    fan_r = fan_s * np.tan(np.deg2rad(fan.spread//2))\n",
    "    circ_c_points = np.cos(np.deg2rad(np.arange(0,180,10)))\n",
    "    circ_s_points = np.sin(np.deg2rad(np.arange(0,180,10)))\n",
    "    xp = np.hstack([0,\n",
    "          fan_s,\n",
    "          fan_s+fan_r*circ_s_points,\n",
    "          fan_s,\n",
    "          0\n",
    "         ])\n",
    "    yp = np.hstack([0,\n",
    "          fan_r,\n",
    "          fan_r*circ_c_points,\n",
    "          -fan_r,\n",
    "          0\n",
    "         ])\n",
    "    rx,ry = np.cos(np.deg2rad(fan.angle)), np.sin(np.deg2rad(fan.angle))\n",
    "    rot = np.array([[rx,-ry],[ry,rx]])\n",
    "    xr,yr=np.dot(rot,np.vstack([xp,yp]))\n",
    "\n",
    "    return (xc+xr, yc+yr)\n",
    "\n",
    "def blotch_mask(blotch, tile):\n",
    "    xc,yc = blotch.image_x - (tile.x_hirise-nx//2),blotch.image_y - (tile.y_hirise-ny//2)\n",
    "\n",
    "    t = np.linspace(0, 2*np.pi, 22)\n",
    "    xp = blotch.radius_1 * np.cos(t)\n",
    "    yp = blotch.radius_2 * np.sin(t)\n",
    "\n",
    "    rx,ry = np.cos(np.deg2rad(blotch.angle)), np.sin(np.deg2rad(blotch.angle))\n",
    "    rot = np.array([[rx,-ry],[ry,rx]])\n",
    "    xr,yr=np.dot(rot,np.vstack([xp,yp]))\n",
    "\n",
    "    return (xc+xr, yc+yr)\n",
    "\n",
    "\n",
    "def get_image(tiles_coord, jp, irow):\n",
    "    row = tiles_coord.iloc[irow]\n",
    "    sx = slice(int(row.x_hirise-nx//2),int(row.x_hirise+nx//2))\n",
    "    sy = slice(int(row.y_hirise-ny//2),int(row.y_hirise+ny//2))\n",
    "    im16 = np.copy(jp[sy,sx])\n",
    "    ratio = np.amax(im16) / 256\n",
    "    img8 = (im16 / ratio).astype('uint8')\n",
    "    return img8\n",
    "\n",
    "def show_image(tiles_coord, fan_or_blotch, jp, irow, isfan=True):\n",
    "    \"\"\"\n",
    "    isfan: True for fan and False for blotch\n",
    "    \"\"\"\n",
    "    row = tiles_coord.loc[irow]\n",
    "    img8 = get_image(tiles_coord, jp, irow)\n",
    "    cv2_imshow(img8)\n",
    "\n",
    "    if isfan:\n",
    "      myfans = fan_or_blotch[fan_or_blotch.tile_id == tiles_coord.loc[irow].tile_id]\n",
    "      for ifan, fan in myfans.iterrows():\n",
    "            \n",
    "            x,y = fan_mask(fan, row)\n",
    "            x = np.where(x<0, 1, x) \n",
    "            y = np.where(y<0, 1, y) \n",
    "            x = np.where(x>nx, nx - 1, x) \n",
    "            y = np.where(y>ny, ny - 1, y) \n",
    "            plt.plot(x,y,alpha=1.0)\n",
    "            \n",
    "    \n",
    "#     else:\n",
    "#       myblotches = fan_or_blotch[fan_or_blotch.tile_id == tiles_coord.loc[irow].tile_id]\n",
    "#       print(tiles_coord.loc[irow].tile_id)\n",
    "#       for iblotch, blotch in myblotches.iterrows():\n",
    "#           x,y = blotch_mask(blotch, row)\n",
    "#           plt.plot(x,y,alpha=1.0) # Removed since we do not need blotches, false will imply no fans shown\n",
    "\n",
    "    return img8 # This will return an array as well\n",
    "\n",
    "# for irow in [19,100]:\n",
    "#     row = tiles_coord.iloc[irow]\n",
    "#     jp = load_file(row.obsid)\n",
    "#     plt.figure(figsize = (16,8))\n",
    "#     show_image(tiles_coord, fan, jp, irow, isfan = True)\n",
    "    \n",
    "# print(show_image(tiles_coord, fan, jp, 100, isfan = True)) # (NO LONGER) Gives and error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fan_box_marking_id(tiles_coord, jp, irow):\n",
    "    row = tiles_coord.iloc[irow]\n",
    "    jp = load_file(row.obsid)\n",
    "    img = get_image(tiles_coord, jp, irow)\n",
    "    row = tiles_coord.loc[irow]\n",
    "    img8 = get_image(tiles_coord, jp, irow)\n",
    "    marking_id_list = []\n",
    "\n",
    "    myfans = fan[fan.tile_id == tiles_coord.loc[irow].tile_id]\n",
    "    for ifan, fan0 in myfans.iterrows():\n",
    "        marking_id_list.append(myfans.marking_id[ifan])     \n",
    "        \n",
    "    if len(marking_id_list) == 0:\n",
    "        return [None]\n",
    "    return marking_id_list\n",
    "\n",
    "def extract_fan_box(tiles_coord, jp, irow, loc_list):\n",
    "    row = tiles_coord.loc[irow]\n",
    "    img8 = get_image(tiles_coord, jp, irow)\n",
    "    cropped = []\n",
    "    myfans = fan[fan.tile_id == tiles_coord.loc[irow].tile_id]\n",
    "\n",
    "    for ifan, fan0 in myfans.iterrows():\n",
    "        x,y = fan_mask(fan0, row)\n",
    "        x = np.where(x<0, 1, x) \n",
    "        y = np.where(y<0, 1, y) \n",
    "        x = np.where(x>nx, nx - 1, x) \n",
    "        y = np.where(y>ny, ny - 1, y)\n",
    "        min_x = int(min(x))\n",
    "        max_x = int(max(x))\n",
    "        min_y = int(min(y))\n",
    "        max_y = int(max(y))\n",
    "        cropped.append(img8[min_y:max_y, min_x:max_x])\n",
    "        width = abs(max_x - min_x)\n",
    "        height = abs(max_y - min_y)\n",
    "        loc_list.append([(min_x, min_y), width, height])\n",
    "\n",
    "    if cropped == []:\n",
    "        return [None]\n",
    "    else:\n",
    "        return cropped # List of img8 files of cropped fan images\n",
    "\n",
    "def intersection(arr1, arr2):\n",
    "    p1 = pd.DataFrame([r.flatten() for r in arr1]).drop_duplicates()\n",
    "    p2 = pd.DataFrame([r.flatten() for r in arr2]).drop_duplicates()\n",
    "    res = p1.merge(p2)\n",
    "    return res\n",
    "\n",
    "def random_square_edges(threshold_size = 25):\n",
    "    x1 = randint(0, nx - 1)\n",
    "    y1 = randint(0, ny - 1)\n",
    "    x2 = randint(0, nx - 1)\n",
    "    y2 = randint(0, ny - 1) \n",
    "    \n",
    "    if abs(y2-y1) < threshold_size:\n",
    "#         print(\"random_square_edges() FAILED BOX SIZE: Trying again\")\n",
    "        return random_square_edges(threshold_size)\n",
    "\n",
    "    if abs(x2-x1) < threshold_size:\n",
    "#         print(\"random_square_edges() FAILED BOX SIZE: Trying again\")\n",
    "        return random_square_edges(threshold_size)\n",
    "        \n",
    "    if x1>x2 and y1>y2:\n",
    "        x_low = x2\n",
    "        x_high = x1\n",
    "        y_low = y2\n",
    "        y_high = y1\n",
    "        \n",
    "    if x1>x2 and y2>y1:\n",
    "        x_low = x2\n",
    "        x_high = x1\n",
    "        y_low = y1\n",
    "        y_high = y2\n",
    "        \n",
    "    if x2>x1 and y1>y2:\n",
    "        x_low = x1\n",
    "        x_high = x2\n",
    "        y_low = y2\n",
    "        y_high = y1\n",
    "        \n",
    "    if x2>x1 and y2>y1:\n",
    "        x_low = x1\n",
    "        x_high = x2\n",
    "        y_low = y1\n",
    "        y_high = y2\n",
    "        \n",
    "    return x_low, x_high, y_low, y_high\n",
    "\n",
    "def square_generator(xmin, xmax, ymin, ymax):\n",
    "    xrun = np.arange(xmin, xmax, 1)\n",
    "    x = np.array([])\n",
    "    y = np.array([])\n",
    "    \n",
    "    for xval in xrun:\n",
    "        yline = np.arange(ymin, ymax, 1)\n",
    "        xline = np.linspace(xval, xval, len(yline))\n",
    "        x = np.append(x, xline)\n",
    "        y = np.append(y, yline)\n",
    "    return x,y\n",
    "\n",
    "def extract_random_box(tiles_coord, jp, irow, loc_list ,check_intersection = False):\n",
    "    \"\"\" This function extracts a random box which is not a fan but may be a blotch\n",
    "    \"\"\"\n",
    "    \n",
    "    row = tiles_coord.iloc[irow]\n",
    "    jp = load_file(row.obsid)\n",
    "    img = get_image(tiles_coord, jp, irow)\n",
    "    row = tiles_coord.loc[irow]\n",
    "    img8 = get_image(tiles_coord, jp, irow)\n",
    "\n",
    "    myfans = fan[fan.tile_id == tiles_coord.loc[irow].tile_id]\n",
    "    \n",
    "    fansx = np.array([])\n",
    "    fansy = np.array([])\n",
    "    \n",
    "    x_low, x_high, y_low, y_high = random_square_edges(threshold_size = 20)\n",
    "\n",
    "        \n",
    "    if check_intersection:\n",
    "        for ifan, fan0 in myfans.iterrows():\n",
    "            x,y = fan_mask(fan0, row)\n",
    "            x = np.where(x<0, 1, x) \n",
    "            y = np.where(y<0, 1, y) \n",
    "            x = np.where(x>nx, nx - 1, x) \n",
    "            y = np.where(y>ny, ny - 1, y)\n",
    "            xtemp, ytemp = square_generator(min(x), max(x), min(y), max(y))\n",
    "            xtemp, ytemp = np.round(xtemp), np.round(ytemp)\n",
    "            fansx = np.append(fansx, xtemp)\n",
    "            fansy = np.append(fansy, ytemp)\n",
    "    #         plt.plot(xtemp,ytemp, alpha = 0.3, color = \"g\")        \n",
    "        X,Y = square_generator(x_low, x_high, y_low, y_high)\n",
    "        arr1 = np.vstack((fansx,fansy)).T\n",
    "        arr2 = np.vstack((X,Y)).T\n",
    "        intersect = intersection(arr1, arr2)\n",
    "        if intersect.size != 0:\n",
    "#             print(\"extract_random_box() FAILED INTERSECTION: Trying again\")\n",
    "            return extract_random_box(tiles_coord, jp, irow, check_intersection = True) #If intersecting with fan masks, recurse. \n",
    "        \n",
    "        maxx, minx = int(max(X)), int(min(X))\n",
    "        maxy, miny = int(max(Y)), int(min(Y))\n",
    "#     cv2_imshow(img8)\n",
    "#     plt.plot(X,Y, alpha = 0.3, color = \"r\")\n",
    "    else:\n",
    "        maxx, minx = int(x_high), int(x_low)\n",
    "        maxy, miny = int(y_high), int(y_low)\n",
    "    \n",
    "    width = abs(maxx - minx)\n",
    "    height = abs(maxy - miny)\n",
    "    loc_list += [(minx, miny), width, height]\n",
    "    \n",
    "    return img8[miny:maxy, minx:maxx]\n",
    "\n",
    "def plot_bar(y, loc='left', relative=True):\n",
    "    width = 0.35\n",
    "    if loc == 'left':\n",
    "        n = -0.5\n",
    "    elif loc == 'right':\n",
    "        n = 0.5\n",
    " \n",
    "    # calculate counts per type and sort, to ensure their order\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    sorted_index = np.argsort(unique)\n",
    "    unique = unique[sorted_index]\n",
    " \n",
    "    if relative:\n",
    "        # plot as a percentage\n",
    "        counts = 100*counts[sorted_index]/len(y)\n",
    "        ylabel_text = '% count'\n",
    "    else:\n",
    "        # plot counts\n",
    "        counts = counts[sorted_index]\n",
    "        ylabel_text = 'count'\n",
    " \n",
    "    xtemp = np.arange(len(unique))\n",
    " \n",
    "    plt.bar(xtemp + n*width, counts, align='center', alpha=.7, width=width)\n",
    "    plt.xticks(xtemp, unique)\n",
    "    plt.xlabel('Label Type')\n",
    "    plt.ylabel(ylabel_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "blotch = pd.read_csv(P4data_location + \"/P4_catalog_v1.1_L1C_cut_0.5_blotch.csv\")\n",
    "\n",
    "def extract_blotch_box_marking_id(tiles_coord, jp, irow):\n",
    "    row = tiles_coord.iloc[irow]\n",
    "    jp = load_file(row.obsid)\n",
    "    img = get_image(tiles_coord, jp, irow)\n",
    "    img8 = get_image(tiles_coord, jp, irow)\n",
    "    marking_id_list = []\n",
    "\n",
    "    myblotches = blotch[blotch.tile_id == tiles_coord.loc[irow].tile_id]\n",
    "    \n",
    "    for iblotch, blotch0 in myblotches.iterrows():\n",
    "        marking_id_list.append(myblotches.marking_id[iblotch])     \n",
    "        \n",
    "    if len(marking_id_list) == 0:\n",
    "        return [None]\n",
    "    return marking_id_list\n",
    "\n",
    "def extract_blotch_box(tiles_coord, jp, irow, loc_list):\n",
    "    row = tiles_coord.loc[irow]\n",
    "    img8 = get_image(tiles_coord, jp, irow)\n",
    "    cropped = []\n",
    "    myblotches = blotch[blotch.tile_id == tiles_coord.loc[irow].tile_id]\n",
    "\n",
    "    for iblotch, blotch0 in myblotches.iterrows():\n",
    "        x,y = blotch_mask(blotch0, row)\n",
    "        x = np.where(x<0, 1, x) \n",
    "        y = np.where(y<0, 1, y) \n",
    "        x = np.where(x>nx, nx - 1, x) \n",
    "        y = np.where(y>ny, ny - 1, y)\n",
    "        min_x = int(min(x))\n",
    "        max_x = int(max(x))\n",
    "        min_y = int(min(y))\n",
    "        max_y = int(max(y))\n",
    "        cropped.append(img8[min_y:max_y, min_x:max_x])\n",
    "        width = abs(max_x - min_x)\n",
    "        height = abs(max_y - min_y)\n",
    "        loc_list.append([(min_x, min_y), width, height])\n",
    "\n",
    "    if cropped == []:\n",
    "        return [None]\n",
    "    else:\n",
    "        return cropped # List of img8 files of cropped fan images\n",
    "    \n",
    "# for i in tqdm([1,2,5,20,29,100,899, 1000, 1001, 1002, 1003, 1004, 1005]):\n",
    "#     irow = i\n",
    "#     row = tiles_coord.iloc[irow]\n",
    "#     jp = load_file(row.obsid)\n",
    "#     img = get_image(tiles_coord, jp, irow)\n",
    "#     marking_id_list = extract_blotch_box_marking_id(tiles_coord, jp, irow)\n",
    "#     loc_list = []\n",
    "#     blotch_boxes = extract_blotch_box(tiles_coord, jp, irow, loc_list)\n",
    "# #     print(loc_list)\n",
    "#     count = 0\n",
    "#     for image in blotch_boxes:\n",
    "#         if image is None:\n",
    "#             continue\n",
    "#         plt.figure()\n",
    "#         plt.title(marking_id_list[count])    \n",
    "#         count += 1\n",
    "#         plt.imshow(image)\n",
    "# #         cv2_imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(img0):\n",
    "    img = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)\n",
    "    img = resize(image = img, output_shape = rescale_size, anti_aliasing=True)\n",
    "#     p2, p98 = np.percentile(img, (5, 95))\n",
    "#     rescaled = exposure.rescale_intensity(img, in_range=(p2, p98))\n",
    "#     sigma = 1.5\n",
    "#     thresh = np.mean(rescaled) -  sigma * np.std(rescaled) \n",
    "#     img = img > threshold_otsu(img)\n",
    "#     img = closing(rescaled < thresh, square(1))\n",
    "#     img = ndi.binary_fill_holes(img)\n",
    "    return img\n",
    "\n",
    "# irow = 8\n",
    "# row = tiles_coord.iloc[irow]\n",
    "# jp = load_file(row.obsid)\n",
    "\n",
    "# plt.figure(figsize = (16,9))\n",
    "# loc_list = []\n",
    "# random_img = extract_fan_box(tiles_coord, jp, irow, loc_list)[0]\n",
    "# plt.imshow(process_image(random_img))\n",
    "# plt.figure()\n",
    "# plt.imshow(random_img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU processors: 8\n",
      "No. Tiles: 42904\n",
      "Total Sample Size: 158476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done   2 tasks      | elapsed:   29.2s\n",
      "[Parallel(n_jobs=8)]: Done   9 tasks      | elapsed:   47.4s\n",
      "[Parallel(n_jobs=8)]: Done  16 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=8)]: Done  25 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=8)]: Done  45 tasks      | elapsed:  3.5min\n",
      "[Parallel(n_jobs=8)]: Done  56 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=8)]: Done  69 tasks      | elapsed:  6.0min\n",
      "[Parallel(n_jobs=8)]: Done  82 tasks      | elapsed:  6.6min\n",
      "[Parallel(n_jobs=8)]: Done  97 tasks      | elapsed:  7.7min\n",
      "[Parallel(n_jobs=8)]: Done 112 tasks      | elapsed:  9.1min\n",
      "[Parallel(n_jobs=8)]: Done 129 tasks      | elapsed: 10.7min\n",
      "[Parallel(n_jobs=8)]: Done 146 tasks      | elapsed: 12.2min\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of CPU processors:\", num_cores)\n",
    "\n",
    "print(\"No. Tiles:\", len(tiles_coord))\n",
    "print(\"Total Sample Size:\", len(fan))\n",
    "\n",
    "data = pd.DataFrame({'tile_id' : [], \"marking_id\": [], \"label\": [], \"item_loc\": [],\"img\": []})\n",
    "\n",
    "data_size = 500\n",
    "\n",
    "skip_factor = len(tiles_coord) // data_size\n",
    "\n",
    "# print(f\"Extracting a tile every {skip_factor} tiles\")\n",
    "\n",
    "def parallel_extract(i, rescale_size, tiles_coord):\n",
    "    i += 3500\n",
    "    data = pd.DataFrame({'tile_id' : [], \"marking_id\": [], \"label\": [], \"item_loc\": [],\"img\": []})\n",
    "    irow = i\n",
    "    row = tiles_coord.iloc[irow]\n",
    "    jp = load_file(row.obsid)\n",
    "    \n",
    "    marking_id_list = extract_fan_box_marking_id(tiles_coord, jp, irow)\n",
    "    marking_id_list_blotch = extract_blotch_box_marking_id(tiles_coord, jp, irow)\n",
    "    fan_locations = []\n",
    "    blotch_locations = []\n",
    "    fan_boxes = extract_fan_box(tiles_coord, jp, irow, fan_locations)\n",
    "    blotch_boxes = extract_blotch_box(tiles_coord, jp, irow, blotch_locations)\n",
    "    \n",
    "    if marking_id_list[0] is None:\n",
    "        marking_id_list.pop(0)\n",
    "        \n",
    "    if marking_id_list_blotch[0] is None:\n",
    "        marking_id_list_blotch.pop(0)\n",
    "    \n",
    "#     assert len(marking_id_list) == len(fan_boxes)\n",
    "    \n",
    "    for k in range(len(marking_id_list_blotch)):\n",
    "        \n",
    "        blotch_box = process_image(blotch_boxes[k])\n",
    "        \n",
    "        boxed_blotch = pd.DataFrame({'tile_id' : [tiles_coord.iloc[irow].tile_id],\n",
    "                            \"marking_id\": [marking_id_list_blotch[k]],\n",
    "                            \"label\": [\"notfan\"], \n",
    "                            \"item_loc\": [blotch_locations[k]],\n",
    "                            \"img\": [blotch_box]})\n",
    "        data = pd.concat([data, boxed_blotch])\n",
    "    \n",
    "    for j in range(len(marking_id_list)):\n",
    "        \n",
    "        fan_box = process_image(fan_boxes[j])\n",
    "        \n",
    "        random_box_loc = []\n",
    "        random_box = extract_random_box(tiles_coord, load_file(tiles_coord.iloc[irow].obsid), irow, random_box_loc)\n",
    "        random_box = process_image(random_box)\n",
    "        \n",
    "#         random_box2_loc = []\n",
    "#         random_box2 = extract_random_box(tiles_coord, load_file(tiles_coord.iloc[irow].obsid), irow, random_box2_loc)\n",
    "#         random_box2 = process_image(random_box2)\n",
    "\n",
    "#         random_box3_loc = []\n",
    "#         random_box3 = extract_random_box(tiles_coord, load_file(tiles_coord.iloc[irow].obsid), irow, random_box3_loc)\n",
    "#         random_box3 = cv2.cvtColor(random_box3, cv2.COLOR_BGR2GRAY)\n",
    "#         random_box3 = resize(image = random_box3, output_shape = rescale_size, anti_aliasing=True)        \n",
    "        \n",
    "        boxed_fan = pd.DataFrame({'tile_id' : [tiles_coord.iloc[irow].tile_id],\n",
    "                            \"marking_id\": [marking_id_list[j]],\n",
    "                            \"label\": [\"fan\"], \n",
    "                            \"item_loc\": [fan_locations[j]],\n",
    "                            \"img\": [fan_box]})\n",
    "        data = pd.concat([data, boxed_fan])\n",
    "        \n",
    "        random = pd.DataFrame({'tile_id' : [tiles_coord.iloc[irow].tile_id],\n",
    "                            \"marking_id\": [\"R\" + marking_id_list[j][1:]],\n",
    "                            \"label\": [\"notfan\"], \n",
    "                            \"item_loc\": [random_box_loc],\n",
    "                            \"img\": [random_box]})\n",
    "        data = pd.concat([data, random])\n",
    "        \n",
    "        \n",
    "#         random2 = pd.DataFrame({'tile_id' : [tiles_coord.iloc[irow].tile_id],\n",
    "#                             \"marking_id\": [\"E\" + marking_id_list[j][1:]],\n",
    "#                             \"label\": [\"notfan\"], \n",
    "#                             \"item_loc\": [random_box2_loc],\n",
    "#                             \"img\": [random_box2]})\n",
    "#         data = pd.concat([data, random2])\n",
    "\n",
    "#         random3 = pd.DataFrame({'tile_id' : [tiles_coord.iloc[irow].tile_id],\n",
    "#                             \"marking_id\": [\"Q\" + marking_id_list[j][1:]],\n",
    "#                             \"label\": [\"notfan\"], \n",
    "#                             \"item_loc\": [random_box3_loc],\n",
    "#                             \"img\": [random_box3]})\n",
    "#         data = pd.concat([data, random3])\n",
    "    return data\n",
    "\n",
    "# with parallel_backend('threading', n_jobs=4):\n",
    "current = Parallel(n_jobs = num_cores, verbose=10, prefer = 'threads')(delayed(parallel_extract)\\\n",
    "                                                  (i, rescale_size, tiles_coord) for i in range(data_size))\n",
    "all_data = pd.concat(current)\n",
    "data = pd.concat([data, all_data])\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "print(\"Current Sample Size:\" , data.shape[0])\n",
    "\n",
    "t = time.time()\n",
    "data.to_pickle(f\"data{data_size}.p\", protocol = 3)\n",
    "print(f\"Write time: {round(time.time() - t, 2)}s\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn.config_context(assume_finite=True)\n",
    "\n",
    "# data_size_to_extract = 1000\n",
    "# t = time.time()\n",
    "# data = pd.read_pickle(f\"data{data_size_to_extract}.p\")\n",
    "# print(f\"Read time: {round(time.time() - t, 2)}s\")\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['img']\n",
    "y = data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "print(X[0].shape)\n",
    "print(X.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "img = X[0]\n",
    " \n",
    "# scale down the image to one third\n",
    "img = rescale(img, 1/3, mode='reflect') \n",
    "\n",
    "# calculate the hog and return a visual representation.\n",
    "img_hog, img_hog_img = hog(img,\n",
    "                           pixels_per_cell=(12, 12),\n",
    "                           cells_per_block=(2,2),\n",
    "                           orientations=8,\n",
    "                           visualize=True,\n",
    "                           block_norm='L2-Hys')\n",
    " \n",
    "fig, ax = plt.subplots(1,2)\n",
    "fig.set_size_inches(16,12)\n",
    "# # remove ticks and their labels\n",
    "# [a.tick_params(bottom=False, left=False, labelbottom=False, labelleft=False)\n",
    "#     for a in ax]\n",
    " \n",
    "ax[0].imshow(img)\n",
    "ax[0].set_title('img')\n",
    "ax[1].imshow(img_hog_img, cmap='gray')\n",
    "ax[1].set_title('img hog')\n",
    "print('\\nNumber of pixels: ', img.shape[0] * img.shape[1])\n",
    "print('Number of hog features: ', img_hog.shape[0])\n",
    "\n",
    "plt.figure(figsize = (12,6))\n",
    "plt.suptitle(\"Photo's per type\")\n",
    "plot_bar(y_train, loc='left')\n",
    "plot_bar(y_test, loc='right')\n",
    "plt.legend([\n",
    "    'train ({0} photos)'.format(len(y_train)),\n",
    "    'test ({0} photos)'.format(len(y_test))\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HogTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Expects an array of 2d arrays (1 channel images)\n",
    "    Calculates hog features for each img\n",
    "    \"\"\"\n",
    " \n",
    "    def __init__(self, y=None, orientations=9,\n",
    "                 pixels_per_cell=(8, 8),\n",
    "                 cells_per_block=(3, 3), block_norm='L2-Hys'):\n",
    "        self.y = y\n",
    "        self.orientations = orientations\n",
    "        self.pixels_per_cell = pixels_per_cell\n",
    "        self.cells_per_block = cells_per_block\n",
    "        self.block_norm = block_norm\n",
    " \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    " \n",
    "    def transform(self, X, y=None):\n",
    " \n",
    "        def local_hog(X):\n",
    "            return hog(X,\n",
    "                       orientations=self.orientations,\n",
    "                       pixels_per_cell=self.pixels_per_cell,\n",
    "                       cells_per_block=self.cells_per_block,\n",
    "                       block_norm=self.block_norm)\n",
    " \n",
    "        try: # parallel\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "        except:\n",
    "            return np.array([local_hog(img) for img in X])\n",
    "\n",
    "        \n",
    "hogify = HogTransformer(\n",
    "            pixels_per_cell=(15, 15),\n",
    "            cells_per_block=(3,3),\n",
    "            orientations=20,\n",
    "            block_norm='L2-Hys')\n",
    "\n",
    "scalify = StandardScaler()\n",
    "\n",
    "SGD =  SGDClassifier(max_iter=1000, tol=1e-2, loss = \"hinge\", \n",
    "                     random_state = seed, warm_start = True, \n",
    "                     n_iter_no_change= 100, verbose = 1)\n",
    "\n",
    "LR = LogisticRegression(random_state = seed, solver = 'saga', verbose = 1, n_jobs = num_cores//2 )\n",
    "SVCl = SVC(kernel='rbf', random_state = seed)\n",
    "\n",
    "# models = []\n",
    "# models.append(('LR', LR))\n",
    "# models.append(('LDA', LinearDiscriminantAnalysis()))\n",
    "# models.append(('KNN', KNeighborsClassifier()))\n",
    "# models.append(('CART', DecisionTreeClassifier(random_state = seed)))\n",
    "# models.append(('RF', RandomForestClassifier(n_estimators=100, random_state = seed)))\n",
    "# models.append(('NB', GaussianNB()))\n",
    "# models.append(('SVM-l', SVCl))\n",
    "# models.append(('SVM-rbf', SVC(kernel='rbf', random_state = seed)))\n",
    "# models.append(('SVM-poly', SVC(kernel='poly', random_state = seed)))\n",
    "# models.append(('SGD', SGD)) #Basically SVM\n",
    "\n",
    "# # variables to hold the results and names\n",
    "# results0 = []\n",
    "# names   = []\n",
    "\n",
    "# X_train_hog = hogify.fit_transform(X_train)\n",
    "# X_train_processed = scalify.fit_transform(X_train_hog)\n",
    "\n",
    "# # 10-fold cross validation\n",
    "# def ml_comparison(name, model, seed):\n",
    "#     scoring = \"accuracy\"\n",
    "#     t = time.time()\n",
    "#     kfold = KFold(n_splits=10, random_state = seed)\n",
    "#     cv_results = cross_val_score(model, X_train_processed, y_train, cv=kfold, scoring=scoring)\n",
    "#     run_time = round(time.time() - t)\n",
    "#     return cv_results, name, run_time, cv_results.mean()\n",
    "\n",
    "# current = Parallel(n_jobs = num_cores//4, verbose=8)(delayed(ml_comparison)(name, model, seed) for name, model in models)\n",
    "\n",
    "# while current[0] == []:\n",
    "#     current.pop(0)\n",
    "\n",
    "# temp = list(zip(*current))\n",
    "# results0 = temp[0]\n",
    "# names = temp[1]\n",
    "# run_times = temp[2]    \n",
    "# accuracies = temp[3]    \n",
    "\n",
    "# for i in range(len(run_times)):\n",
    "#     left_aligned = f\"{names[i]}:\"\n",
    "#     center = f\"{round(accuracies[i], 5)}\"\n",
    "#     right_aligned = f\"({run_times[i]}s)\"\n",
    "#     print(f\"{left_aligned:<10}{center:^10}{right_aligned:>10}\")\n",
    "\n",
    "# # boxplot algorithm comparison\n",
    "# import seaborn as sns\n",
    "# fig = plt.figure(figsize = (15,6))\n",
    "# fig.suptitle('ML Algorithm Comparison')\n",
    "# sns.set(style=\"ticks\", palette=\"pastel\")\n",
    "# ax = sns.boxplot(data = results0)\n",
    "# ax.set_xticklabels(names)\n",
    "# ax.set_ylabel(\"Accuracy\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HOG_pipeline = Pipeline([\n",
    "    ('hogify', HogTransformer(\n",
    "        pixels_per_cell=(15, 15),\n",
    "        cells_per_block=(3,3),\n",
    "        orientations=20,\n",
    "        block_norm='L2-Hys')\n",
    "    ),\n",
    "    ('scalify', StandardScaler()),\n",
    "    ('classify', SGD)\n",
    "#     ('classify', SVCl)\n",
    "#     ('classify', LR)\n",
    "])\n",
    " \n",
    "param_grid = [\n",
    "    {'hogify__orientations': [18],\n",
    "     'hogify__cells_per_block': [(3, 3)],\n",
    "     'hogify__pixels_per_cell': [(15, 15)],\n",
    "     'classify': [SGD, LR]}\n",
    "]    \n",
    "\n",
    "grid_search = GridSearchCV(HOG_pipeline,\n",
    "                           param_grid,\n",
    "                           cv=3,\n",
    "                           n_jobs= num_cores//4,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=10,\n",
    "                           return_train_score=True)\n",
    "t1 = time.time()\n",
    "# clf = grid_search.fit(X_train, y_train) # Usually 4% more than HOG_pipline direct\n",
    "clf = HOG_pipeline.fit(X_train, y_train)\n",
    "t2 = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "print(f\"Total Runtime: {round(t2-t1, 2)}s\\n\")\n",
    "# print(\"Best Config:\", clf.best_params_)\n",
    "# print(clf.best_estimator_)\n",
    "# print(f'Train Data Best Score: {clf.best_score_ * 100}')\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "index = X_test.index[0]\n",
    "cmx = confusion_matrix(y_test, y_pred)\n",
    "data_predictions = pd.DataFrame(data=y_pred, index= X_test.index)\n",
    "print('X_test Percentage correct: ', accuracy_score(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", cmx)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# def extract_image(tile_id, item_loc):\n",
    "#     row = tiles_coord[tiles_coord.tile_id == tile_id].squeeze()\n",
    "#     irow = row.name\n",
    "#     jp = load_file(row.obsid)\n",
    "#     img8 = get_image(tiles_coord, jp, irow)\n",
    "#     minx = item_loc[0][0]\n",
    "#     miny = item_loc[0][1]\n",
    "#     maxx = minx + item_loc[1]\n",
    "#     maxy = miny + item_loc[2]\n",
    "#     processing0 = img8[miny:maxy, minx:maxx]\n",
    "#     processing1 = cv2.cvtColor(processing0, cv2.COLOR_BGR2GRAY)\n",
    "#     processing2 = resize(image = processing1, output_shape = rescale_size, anti_aliasing=True)\n",
    "#     extracted_image = processing2\n",
    "#     row['img'] = extracted_image\n",
    "#     return extracted_image\n",
    "\n",
    "# with open(\"classify_false_negative.json\", \"r\") as f:\n",
    "#     load = json.load(f)\n",
    "#     f.close()\n",
    "\n",
    "# predicted_fans = pd.DataFrame(load)#.sort_values(by=['tile_id'])\n",
    "# predicted_fans[\"isfan\"].replace({0: \"notfan\", 1: \"fan\"}, inplace=True)\n",
    "\n",
    "# # [(minx, miny), width, height]\n",
    "# item_loc = [(predicted_fans.bbox[0][0], predicted_fans.bbox[0][1]),\n",
    "#             predicted_fans.bbox[0][2],\n",
    "#             predicted_fans.bbox[0][3]]\n",
    "\n",
    "# predicted_fans.loc[:, 'item_loc'] = predicted_fans.bbox.map(lambda x: [(int(x[0]), int(x[1])),\n",
    "#                                                                         int(x[2]), int(x[3])])\n",
    "# predicted_fans = predicted_fans.drop(columns = ['bbox']).rename(columns={'isfan':'label'})\n",
    "\n",
    "# predicted_fans['img'] = 1\n",
    "\n",
    "# n = 1000\n",
    "\n",
    "# predicted_fans = predicted_fans.head(n)\n",
    "\n",
    "# print(f\"Tasks: {predicted_fans.shape[0]}\" )\n",
    "    \n",
    "# extracted_list = Parallel(n_jobs = num_cores, verbose=6, prefer = 'threads')\\\n",
    "#                     (delayed(extract_image)(predicted_fans.iloc[i].tile_id,\n",
    "#                                             predicted_fans.iloc[i].item_loc) for i in range(predicted_fans.shape[0]))\n",
    "\n",
    "# predicted_fans['img'] = pd.Series(extracted_list)\n",
    "\n",
    "# t = time.time()\n",
    "# predicted_fans.to_pickle(f\"classify_false_negative{n}.p\", protocol = 3)\n",
    "# print(f\"Write time: {round(time.time() - t, 2)}s\")\n",
    "\n",
    "# predicted_fans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "predicted_fans = pd.read_pickle(\"classify_false_negative1000.p\")\n",
    "print(f\"Read time: {round(time.time() - t, 2)}s\")\n",
    "predicted_fans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "predictions = clf.predict(predicted_fans['img'])\n",
    "predicted_fans['prediction'] = predictions\n",
    "pred = predicted_fans['prediction']\n",
    "predicted_fans.drop(labels=['prediction'], axis=1,inplace = True)\n",
    "predicted_fans.insert(2, 'prediction', pred)\n",
    "y_test = predicted_fans['label']\n",
    "cmx = confusion_matrix(y_test, predictions)\n",
    "print('Prediction Percentage Overlap: ', accuracy_score(predictions, y_test))\n",
    "print(\"Confusion Matrix:\\n\", cmx)\n",
    "# print(\"\\nClassification Report:\\n\", classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "center"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (10,7))\n",
    "group_names = ['We all agree these are fan',\n",
    "               'Aslesha and I say fan \\n Ground truth say not fan',\n",
    "               'Aslesha and ground truth say fan \\n I say not fan',\n",
    "               'Ground truth and I say not fans \\n Aslesha says fans']\n",
    "# group_names = [\"ground truth says blotch\",\n",
    "#                \"ground truth says blotch\",\n",
    "#                \"ground truth says blotch\",\n",
    "#                \"ground truth says neither\",\n",
    "#                \"ground truth says neither\",\n",
    "#                \"ground truth says neither\",\n",
    "#                \"ground truth says fan\",\n",
    "#                \"ground truth says fan\",\n",
    "#                \"ground truth says fan\"]\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                cmx.flatten()]\n",
    "group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                     cmx.flatten()/np.sum(cmx)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in\n",
    "          zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)\n",
    "sns.heatmap(cmx, annot=labels, fmt='', cmap='Blues')\n",
    "plt.title(\"Percentage Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_iters  = min(len(predicted_fans['img']), 100)\n",
    "results = pd.DataFrame({'tile_id': predicted_fans.tile_id, 'item_loc': predicted_fans.item_loc,\n",
    "                        'prediction': predicted_fans['label'], \n",
    "                        'actual': predictions}, index = predicted_fans['img'].index)\n",
    "\n",
    "results = results.sort_values(by=['tile_id'])\n",
    "results = results.tail(max_iters)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,12)) \n",
    "row = tiles_coord[tiles_coord.tile_id == results.iloc[0].tile_id].squeeze()\n",
    "irow = row.name\n",
    "jp = load_file(row.obsid)\n",
    "img = get_image(tiles_coord, jp, irow)\n",
    "ax.imshow(img)\n",
    "tile_id = results.loc[results.index[0]].tile_id\n",
    "\n",
    "for index, result in tqdm(results.iterrows(), total=results.shape[0]):\n",
    "    row = tiles_coord[tiles_coord.tile_id == result.tile_id].squeeze()\n",
    "    irow = row.name\n",
    "    jp = load_file(row.obsid)\n",
    "    img = get_image(tiles_coord, jp, irow)\n",
    "    \n",
    "    if not tile_id == result.tile_id:\n",
    "        fig, ax = plt.subplots(figsize=(12,12)) \n",
    "        ax.imshow(img)\n",
    "    \n",
    "    rect = Rectangle(result.item_loc[0], width = result.item_loc[1] , \n",
    "                     height = result.item_loc[2],\n",
    "                     fill=False, edgecolor='blue', linewidth=1.5)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "    fontsize = 12\n",
    "    h_offset = 0.32\n",
    "    label = f\"{result.actual}\"\n",
    "    label_ = f\"{result.prediction}\"\n",
    "    ax.text(result.item_loc[0][0], \n",
    "            result.item_loc[0][1] + result.item_loc[2] + 8 + h_offset * fontsize, label_, \n",
    "            fontsize= fontsize, weight='bold', color = \"blue\")\n",
    "\n",
    "    ax.text(result.item_loc[0][0], result.item_loc[0][1] - h_offset * fontsize, label, \n",
    "            fontsize= fontsize, weight='bold', color = \"darkred\")\n",
    "    \n",
    "    tile_id = result.tile_id\n",
    "    ax.set_title(f'{tile_id}')\n",
    "plt.show()\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab = predicted_fans['label']\n",
    "predicted_fans.drop(labels=['label'], axis=1,inplace = True)\n",
    "del predicted_fans['img']\n",
    "predicted_fans.insert(2, 'ground_truth', lab)\n",
    "t1 = time.time()\n",
    "predicted_fans.to_json(\"processed_classify_false_negative.json\")\n",
    "t2 = time.time()\n",
    "print(f\"Write Time: {t2-t1}\")\n",
    "predicted_fans"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
